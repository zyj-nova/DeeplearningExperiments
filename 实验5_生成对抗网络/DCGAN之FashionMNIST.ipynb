{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Lla784m_jKo"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nf9SxGie_jKo"
   },
   "outputs": [],
   "source": [
    "train_sets = torchvision.datasets.FashionMNIST(root='./data/',\n",
    "                                              train=True,\n",
    "                                              download=True,\n",
    "                                              transform = transforms.Compose(\n",
    "                                              [\n",
    "                                                  #transforms.Resize((64, 64)),\n",
    "                                                  transforms.ToTensor()                                              \n",
    "                                              ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2uBwCVQe_jKo"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_loader = torch.utils.data.DataLoader(train_sets,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KrmH0Vv8_jKo"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xzO-aCF8Zeae"
   },
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K_ZlYuUH_jKo"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        input (N, z_dim)\n",
    "        output (N,28,28)\n",
    "        \"\"\"\n",
    "        # transpose convolution\n",
    "        self.transpose_conv_5 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=z_dim, out_channels = 1024, kernel_size=4, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels = 1024, out_channels = 512, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels = 512, out_channels = 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels = 256, out_channels = 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels = 128, out_channels = 1, kernel_size=3, stride=1, padding=0),\n",
    "        )\n",
    "        self.tanh = nn.Tanh()\n",
    "    \n",
    "        \n",
    "    def forward(self,batch):\n",
    "        y = self.transpose_conv_5(batch)\n",
    "        return self.tanh(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VUE_I1MM_jKo"
   },
   "outputs": [],
   "source": [
    "class Discrinator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels= 64, kernel_size=5,stride=2,padding=0,bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=64, out_channels= 128, kernel_size=5,stride=2,padding=0,bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=128, out_channels= 256, kernel_size=4,stride=1,padding=1,bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=256, out_channels= 1, kernel_size=4,stride=2,padding=1,bias=False),\n",
    "        )\n",
    "        self.sigmod = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        \"\"\"\n",
    "        input (batch,1,28,28)\n",
    "        output (batch)\n",
    "        \"\"\"\n",
    "        y = self.conv(batch)\n",
    "        return self.sigmod(y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MPlMCClj_jKp"
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Gfalejn_jKp"
   },
   "outputs": [],
   "source": [
    "z_dim = 100\n",
    "netG = Generator(z_dim).to(device)\n",
    "netD = Discrinator().to(device)\n",
    "\n",
    "netG.apply(weights_init)\n",
    "netD.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1qlHJ1c1_jKp"
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CifDS5BG_jKq"
   },
   "outputs": [],
   "source": [
    "real_label = 1.0\n",
    "fake_label = 0.0\n",
    "lr = 0.001\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AddDqzKx_jKq"
   },
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "img_list = []\n",
    "iters = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for index, batch in enumerate(train_loader):\n",
    "        data = batch[0].to(device)\n",
    "        bs = data.size(0)\n",
    "        \n",
    "        z = torch.randn(bs,z_dim,1,1).to(device)\n",
    "        f_imgs = netG(z)\n",
    "        \n",
    "        r_label = torch.ones((bs)).to(device)\n",
    "        f_label = torch.zeros((bs)).to(device)\n",
    "        \n",
    "        r_logit = netD(data).view(-1)\n",
    "        f_logit = netD(f_imgs).view(-1)\n",
    "        \n",
    "        # compute loss\n",
    "        r_loss = criterion(r_logit, r_label)\n",
    "        f_loss = criterion(f_logit, f_label)\n",
    "        loss_D = (r_loss + f_loss) / 2\n",
    "\n",
    "        # update model\n",
    "        netD.zero_grad()\n",
    "        loss_D.backward()\n",
    "        optimizerD.step()\n",
    "\n",
    "        \"\"\" train G \"\"\"\n",
    "        # leaf\n",
    "        z = torch.randn(bs, z_dim,1,1).to(device)\n",
    "        f_imgs = netG(z)\n",
    "\n",
    "        # dis\n",
    "        f_logit = netD(f_imgs).view(-1)\n",
    "        \n",
    "        # compute loss\n",
    "        loss_G = criterion(f_logit, r_label)\n",
    "\n",
    "        # update model\n",
    "        netG.zero_grad()\n",
    "        loss_G.backward()\n",
    "        optimizerG.step()\n",
    "        \n",
    "        G_losses.append(loss_G.item())\n",
    "        D_losses.append(loss_D.item())\n",
    "        \n",
    "        if index % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f'\n",
    "                  % (epoch, num_epochs, index, len(train_loader),\n",
    "                     loss_D.item(), loss_G.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uQ6CXUfTEU-u"
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2GoFTjPG4Oe-"
   },
   "outputs": [],
   "source": [
    "real_batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DrY9oZ3BEeky"
   },
   "outputs": [],
   "source": [
    "real_batch = next(iter(train_loader))\n",
    "\n",
    "# Plot the real images\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "# Plot the fake images from the last epoch\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Euis93cEqjB"
   },
   "outputs": [],
   "source": [
    "x = torch.randn(128,100,1,1).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uqCVd9CPE0sx"
   },
   "outputs": [],
   "source": [
    "imgs = netG(x).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nKyD2zQOFNET"
   },
   "outputs": [],
   "source": [
    "x = torch.randn(128,100,1,1).to(device)\n",
    "imgs = netG(x)\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(imgs.detach().cpu()[:128], padding=5, normalize=True).cpu(),(1,2,0)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DCGANä¹‹FashionMNIST.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
